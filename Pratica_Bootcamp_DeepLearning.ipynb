{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbZ3nxCqA6/P5C7TW85k4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FilosoDev/experimentos-python/blob/main/Pratica_Bootcamp_DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hauDkNJ3TtoA",
        "outputId": "539dbbf9-4f13-46a6-bbdf-d70270d182fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Collecting optree (from keras)\n",
            "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: namex, optree, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.4.1 namex-0.0.8 optree-0.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_Mkm6PWFyjT"
      },
      "outputs": [],
      "source": [
        "import numpy #importa biblioteca para manipulação de matrizes\n",
        "from matplotlib import pyplot as plt  #importa biblioteca para criação de gráficos\n",
        "\n",
        "#inicio das importações de classes do Keras (modelos de Deep Learning)\n",
        "from keras.datasets import mnist #importa dataset mnist\n",
        "from keras.models import Sequential #importa um modelo sequencial\n",
        "from keras.layers import Dense, Dropout, Input, InputLayer #importa camadas totalmente conectadas\n",
        "from keras.layers import Dropout #importa a estrutura de dropout\n",
        "\n",
        "#from keras.utils import np_utils #importa biblioteca de utilidade do Keras\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() #importa o dataset Mnist da biblioteca do Keras\n",
        "print(X_train.shape) #imprime o tamanho do vetor\n",
        "\n",
        "first_image = X_train[7] #obtém a imagem de treino no índice 100 do vetor\n",
        "#realiza a manipulação dos dados da imagem\n",
        "first_image = numpy.array(first_image, dtype='float')\n",
        "pixels = first_image.reshape((28,28))\n",
        "#exibe a imagem do vetor\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(y_train[7]) #imprime a classe da imagem de treino do índice 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "e4SQA2ZLGBG1",
        "outputId": "039f94fc-b596-4ee1-bfd1-5997964ea8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2] #calcula o total de pixels da imagem\n",
        "print(num_pixels)\n",
        "\n",
        "#transforma os valores dos pixels para float32\n",
        "X_train2 = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test2 = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "#normalizando os valores dos pixels entre 0 e 1\n",
        "X_train2 = X_train2 / 255\n",
        "X_test2 = X_test2 / 255\n",
        "\n",
        "print(X_train[7])\n",
        "print(X_train2[7])\n",
        "\n",
        "#print(first_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VP_qbLYqMz6",
        "outputId": "216ea20b-7e99-4376-d9f1-e630339affd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  38  43 105 255 253 253 253\n",
            "  253 253 174   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  43 139 224 226 252 253 252 252 252\n",
            "  252 252 252 158  14   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 178 252 252 252 252 253 252 252 252\n",
            "  252 252 252 252  59   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 109 252 252 230 132 133 132 132 189\n",
            "  252 252 252 252  59   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   4  29  29  24   0   0   0   0  14\n",
            "  226 252 252 172   7   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  85\n",
            "  243 252 252 144   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  88 189\n",
            "  252 252 252  14   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  91 212 247 252\n",
            "  252 252 204   9   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  32 125 193 193 193 253 252 252 252\n",
            "  238 102  28   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  45 222 252 252 252 252 253 252 252 252\n",
            "  177   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  45 223 253 253 253 253 255 253 253 253\n",
            "  253  74   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  31 123  52  44  44  44  44 143 252\n",
            "  252  74   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15 252\n",
            "  252  74   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 252\n",
            "  252  74   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   5  75   9   0   0   0   0   0   0  98 242 252\n",
            "  252  74   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  61 183 252  29   0   0   0   0  18  92 239 252 252\n",
            "  243  65   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 208 252 252 147 134 134 134 134 203 253 252 252 188\n",
            "   83   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 208 252 252 252 252 252 252 252 252 253 230 153   8\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  49 157 252 252 252 252 252 217 207 146  45   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   7 103 235 252 172 103  24   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.14901961 0.16862746 0.4117647  1.         0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.68235296 0.02352941\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.16862746 0.54509807 0.8784314\n",
            " 0.8862745  0.9882353  0.99215686 0.9882353  0.9882353  0.9882353\n",
            " 0.9882353  0.9882353  0.9882353  0.61960787 0.05490196 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.69803923 0.9882353  0.9882353  0.9882353  0.9882353\n",
            " 0.99215686 0.9882353  0.9882353  0.9882353  0.9882353  0.9882353\n",
            " 0.9882353  0.9882353  0.23137255 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.42745098\n",
            " 0.9882353  0.9882353  0.9019608  0.5176471  0.52156866 0.5176471\n",
            " 0.5176471  0.7411765  0.9882353  0.9882353  0.9882353  0.9882353\n",
            " 0.23137255 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.01568628 0.11372549 0.11372549\n",
            " 0.09411765 0.         0.         0.         0.         0.05490196\n",
            " 0.8862745  0.9882353  0.9882353  0.6745098  0.02745098 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.33333334 0.9529412  0.9882353\n",
            " 0.9882353  0.5647059  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.34509805 0.7411765  0.9882353  0.9882353  0.9882353  0.05490196\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.35686275 0.83137256 0.96862745 0.9882353\n",
            " 0.9882353  0.9882353  0.8        0.03529412 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.1254902  0.49019608 0.75686276 0.75686276 0.75686276\n",
            " 0.99215686 0.9882353  0.9882353  0.9882353  0.93333334 0.4\n",
            " 0.10980392 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.1764706  0.87058824\n",
            " 0.9882353  0.9882353  0.9882353  0.9882353  0.99215686 0.9882353\n",
            " 0.9882353  0.9882353  0.69411767 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.8745098  0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 1.         0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.2901961  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.12156863 0.48235294 0.20392157 0.17254902 0.17254902\n",
            " 0.17254902 0.17254902 0.56078434 0.9882353  0.9882353  0.2901961\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.05882353 0.9882353  0.9882353  0.2901961  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.3372549  0.9882353\n",
            " 0.9882353  0.2901961  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.01960784 0.29411766\n",
            " 0.03529412 0.         0.         0.         0.         0.\n",
            " 0.         0.38431373 0.9490196  0.9882353  0.9882353  0.2901961\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.23921569 0.7176471  0.9882353  0.11372549 0.\n",
            " 0.         0.         0.         0.07058824 0.36078432 0.9372549\n",
            " 0.9882353  0.9882353  0.9529412  0.25490198 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.8156863\n",
            " 0.9882353  0.9882353  0.5764706  0.5254902  0.5254902  0.5254902\n",
            " 0.5254902  0.79607844 0.99215686 0.9882353  0.9882353  0.7372549\n",
            " 0.3254902  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.8156863  0.9882353  0.9882353\n",
            " 0.9882353  0.9882353  0.9882353  0.9882353  0.9882353  0.9882353\n",
            " 0.99215686 0.9019608  0.6        0.03137255 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.19215687 0.6156863  0.9882353  0.9882353  0.9882353\n",
            " 0.9882353  0.9882353  0.8509804  0.8117647  0.57254905 0.1764706\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.02745098 0.40392157 0.92156863 0.9882353  0.6745098  0.40392157\n",
            " 0.09411765 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transforma os y em one-hot vector\n",
        "y_train_h = to_categorical(y_train)\n",
        "y_test_h = to_categorical(y_test)\n",
        "\n",
        "#obtém o número de classes do problema\n",
        "num_classes = y_test_h.shape[1]\n",
        "\n",
        "print(num_pixels)\n",
        "print(y_train[1001])\n",
        "print(y_train_h[1001])\n",
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kec6cfHH1T-y",
        "outputId": "d0f9312a-e3cd-4166-f602-e267a302f6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784\n",
            "7\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cria um modelo do tipo sequencial\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(num_pixels,)))  #cria a camada de entrada\n",
        "model.add(Dense(1024, kernel_initializer='normal', activation='relu')) #cria a primeira camada da rede\n",
        "model.add(Dense(2048, kernel_initializer='normal', activation='relu')) #cria a segunda camada da rede\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax')) #cria a camada de saída\n",
        "\n",
        "model.summary() #imprime informaçoes sobre o modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "9U9qp5OdLEpp",
        "outputId": "09abacde-905a-4154-ad94-8ed5f0c8c7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │         \u001b[38;5;34m803,840\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │       \u001b[38;5;34m2,099,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m20,490\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">803,840</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,923,530\u001b[0m (11.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,923,530</span> (11.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,923,530\u001b[0m (11.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,923,530</span> (11.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='crossentropy', optimizer='adam', metrics=['accuracy']) #compila o modelo criado\n",
        "result = model.fit(X_train2, y_train_h, validation_data=(X_test2, y_test_h), epochs=20, verbose=1, batch_size=100) #executa o treinamento"
      ],
      "metadata": {
        "id": "SLAY4xcSbcrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b9f959-5a86-4cb1-e5fd-0abfaf87c4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 83ms/step - accuracy: 0.9088 - loss: 0.3128 - val_accuracy: 0.9731 - val_loss: 0.0874\n",
            "Epoch 2/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 81ms/step - accuracy: 0.9797 - loss: 0.0662 - val_accuracy: 0.9732 - val_loss: 0.0856\n",
            "Epoch 3/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - accuracy: 0.9864 - loss: 0.0428 - val_accuracy: 0.9763 - val_loss: 0.0721\n",
            "Epoch 4/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 83ms/step - accuracy: 0.9895 - loss: 0.0317 - val_accuracy: 0.9776 - val_loss: 0.0804\n",
            "Epoch 5/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 83ms/step - accuracy: 0.9918 - loss: 0.0258 - val_accuracy: 0.9762 - val_loss: 0.0907\n",
            "Epoch 6/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 83ms/step - accuracy: 0.9928 - loss: 0.0240 - val_accuracy: 0.9808 - val_loss: 0.0742\n",
            "Epoch 7/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 86ms/step - accuracy: 0.9942 - loss: 0.0187 - val_accuracy: 0.9803 - val_loss: 0.0890\n",
            "Epoch 8/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 86ms/step - accuracy: 0.9940 - loss: 0.0200 - val_accuracy: 0.9770 - val_loss: 0.0991\n",
            "Epoch 9/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 86ms/step - accuracy: 0.9951 - loss: 0.0155 - val_accuracy: 0.9741 - val_loss: 0.1152\n",
            "Epoch 10/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 86ms/step - accuracy: 0.9942 - loss: 0.0196 - val_accuracy: 0.9780 - val_loss: 0.0936\n",
            "Epoch 11/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 83ms/step - accuracy: 0.9953 - loss: 0.0165 - val_accuracy: 0.9807 - val_loss: 0.0912\n",
            "Epoch 12/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - accuracy: 0.9967 - loss: 0.0119 - val_accuracy: 0.9806 - val_loss: 0.0905\n",
            "Epoch 13/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 80ms/step - accuracy: 0.9962 - loss: 0.0124 - val_accuracy: 0.9795 - val_loss: 0.0956\n",
            "Epoch 14/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 81ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.9804 - val_loss: 0.0972\n",
            "Epoch 15/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 78ms/step - accuracy: 0.9970 - loss: 0.0105 - val_accuracy: 0.9792 - val_loss: 0.1111\n",
            "Epoch 16/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 81ms/step - accuracy: 0.9961 - loss: 0.0155 - val_accuracy: 0.9810 - val_loss: 0.1010\n",
            "Epoch 17/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 79ms/step - accuracy: 0.9963 - loss: 0.0127 - val_accuracy: 0.9805 - val_loss: 0.1124\n",
            "Epoch 18/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 79ms/step - accuracy: 0.9969 - loss: 0.0125 - val_accuracy: 0.9801 - val_loss: 0.1172\n",
            "Epoch 19/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 81ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9839 - val_loss: 0.0994\n",
            "Epoch 20/20\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 78ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 0.9764 - val_loss: 0.1390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtém a imagem número 1001\n",
        "x = X_train2[50]\n",
        "print(x.shape)\n",
        "x = numpy.expand_dims(x, axis=0)\n",
        "print(x.shape)\n",
        "\n",
        "print(model.predict(x))\n",
        "print(numpy.argmax(model.predict(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TthAXAAEBztp",
        "outputId": "5063b18e-cc71-4f4e-d611-80e233700e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784,)\n",
            "(1, 784)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "[[4.0980698e-35 3.8617249e-27 1.2761703e-27 1.0000000e+00 6.1681863e-37\n",
            "  1.9206764e-34 0.0000000e+00 3.2428748e-30 1.4111222e-26 2.7927431e-28]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "3\n"
          ]
        }
      ]
    }
  ]
}